# Résumé

Associate Professor in the [Department of Artificial Intelligence](https://dia.fi.upm.es) at the [Universidad Politécnica de Madrid](https://www.upm.es). He currently focuses his research on emotion recognition in speech. In the past he has led and participated in R&D projects on multi-robot systems and reconfigurable robotics, computational neuroethology, unmanned aerial vehicles, humanoid robots, vision-based automatic driving and industrial robotics. Links to a brief description of some [research projects](./research.html) and a (probably incomplete) [list of publications](./publications.html).


## Teaching

[Autonomous Robots](https://muia.dia.fi.upm.es/en/) (European MSc in Artificial Intelligence). The course focuses primarily on autonomous navigation of mobile robots. Hybrid state-of-the-art artificial intelligence methods to control robots are studied. Students develop a mini-project to build maps of unknown environments that are used for path planning.

[Robotics](https://www.fi.upm.es/?pagina=1645) (European MSc in Informatics Engineering). The course is based on the development of a project in which hybrid artificial intelligence methods are applied. First, students are introduced to lines of work in robotics, both industrial and autonomous. Then, Students review the state-of-the-art and propose a project on which they work throughout the semester. Project progress is discussed and analyzed on a weekly basis. Finally, students prepare a conference paper and formally present their work.

[Robotics](https://www.fi.upm.es/?id=gcdia) (Bachelor Degree in Data Science and Artificial Inteligence). Introductory course on robotics from the perspective of data science and artificial intelligence. The fundamentals of industrial and autonomous robotics, and sensors and actuators commonly used are studied. Methods of mobile robot control are reviewed and compared. The course also covers imaging and computer vision methods that have direct application in robotics.

## Recent Publications

J. de Lope and M. Graña.
An ongoing review of speech emotion recognition.
_Neurocomputing_, 528:1-11, 2023.
[DOI](https://doi.org/10.1016/j.neucom.2023.01.002)

J. de Lope and M. Graña.
A hybrid time-distributed deep neural architecture for speech emotion recognition.
_International Journal of Neural Systems_, 32(6):2250024, 2022.
[DOI](https://doi.org/10.1142/S0129065722500241)

J. de Lope and M. Graña.
Deep transfer learning-based gaze tracking for behavioral activity recognition.
_Neurocomputing_, 500:518-527, 2022.
[DOI](https://doi.org/10.1016/j.neucom.2021.06.100)

J.A. Nicolás, J. de Lope, and M. Graña.
Data augmentation techniques for speech emotion recognition and deep learning.
In J.M. Ferrández, J.R. Álvarez Sánchez, F. de la Paz, and H. Adeli, editors, _Bio-inspired Systems and Applications: from Robotics to Ambient Intelligence_, LNCS 13259, pages 319-326. Springer Nature, Cham, 2022.
[DOI](https://doi.org/10.1007/978-3-031-06527-9_27)

J. de Lope, E. Hernández, V. Vargas and M. Graña.
Speech emotion recognition by conventional machine learning and deep learning.
In H. Sanjurjo, I. Pastor, P. García, H. Quintián, and E. Corchado, editors, _Hybrid Artificial Intelligent Systems_, LNAI 12886, pages 319-330. Springer Nature, Cham, 2021.
[DOI](http://dx.doi.org/10.1007/978-3-030-86271-8_27)

J. de Lope and M. Graña.
Comparison of labeling methods for behavioral activity classification based on gaze ethograms.
In E. A. de la Cal, J.R. Villar, H. Quintián, and E. Corchado, editors,
_Hybrid Artificial Intelligent Systems_, LNAI 12344, pages 132-144. Springer Nature, Cham, 2020.
[DOI](http://dx.doi.org/10.1007/978-3-030-61705-9_12)

M. Graña, M. Aguilar-Moreno, J. de Lope, I. Baglietto, and X. Garmendia.
Improved activity recognition combining inertial motion sensors and electroencephalogram signals.
_International Journal of Neural Systems_, 30(10):2050053, 2020.
[DOI](http://dx.doi.org/10.1142/S0129065720500537)

J. de Lope and M. Graña.
Behavioral activity recognition based on gaze ethograms.
_International Journal of Neural Systems_, 30(7):2050025, 2020.
[DOI](http://dx.doi.org/10.1142/S0129065720500252)
